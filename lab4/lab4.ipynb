{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Считать в `pandas.DataFrame` любой источник данных: CSV, JSON, Excel-файл, HTML-таблицу и т.п."
      ],
      "metadata": {
        "id": "cV53f9eJLpZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFNQrElCl_0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0caffea-a867-4dd7-ffee-40f1f6963dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
            "0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n",
            "1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n",
            "2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n",
            "3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n",
            "4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n",
            "\n",
            "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
            "0           15+2       bourgris          1500          a-00          1191   \n",
            "1           5+10           a-00          1322     skinnerua          1261   \n",
            "2           5+10         ischia          1496          a-00          1500   \n",
            "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
            "4           30+3      nik221107          1523  adivanov2009          1469   \n",
            "\n",
            "                                               moves opening_eco  \\\n",
            "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
            "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
            "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
            "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
            "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
            "\n",
            "                             opening_name  opening_ply  \n",
            "0        Slav Defense: Exchange Variation            5  \n",
            "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
            "2   King's Pawn Game: Leonardis Variation            3  \n",
            "3  Queen's Pawn Game: Zukertort Variation            3  \n",
            "4                        Philidor Defense            5  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20058 entries, 0 to 20057\n",
            "Data columns (total 16 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   id              20058 non-null  object \n",
            " 1   rated           20058 non-null  bool   \n",
            " 2   created_at      20058 non-null  float64\n",
            " 3   last_move_at    20058 non-null  float64\n",
            " 4   turns           20058 non-null  int64  \n",
            " 5   victory_status  20058 non-null  object \n",
            " 6   winner          20058 non-null  object \n",
            " 7   increment_code  20058 non-null  object \n",
            " 8   white_id        20058 non-null  object \n",
            " 9   white_rating    20058 non-null  int64  \n",
            " 10  black_id        20058 non-null  object \n",
            " 11  black_rating    20058 non-null  int64  \n",
            " 12  moves           20058 non-null  object \n",
            " 13  opening_eco     20058 non-null  object \n",
            " 14  opening_name    20058 non-null  object \n",
            " 15  opening_ply     20058 non-null  int64  \n",
            "dtypes: bool(1), float64(2), int64(4), object(9)\n",
            "memory usage: 2.3+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "df = pd.read_csv('games.csv')\n",
        "\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Датасет и подготовка данных:\n",
        "   - Привести описание датасета.\n",
        "   - Осуществить предобработку данных (избавиться от `null`, убрать некоторые признаки и т.п.) - \"подчистить данные\".\n",
        "   - Закодировать категориальные признаки при необходимости.\n",
        "   - Нормализовать данные.\n",
        "   - Разбить выборку на обучающую и тестовую.\n",
        "     > Далее используем обучающую выборку, в том числе для метрик."
      ],
      "metadata": {
        "id": "lOiGDlQRoI6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цель: предсказание победителя шахматной партии (winner) на основе метаданных игры.\n",
        "Признаки:\n",
        "- rated: является ли игра рейтинговой\n",
        "- created_at / last_move_at: временные метки начала и окончания\n",
        "- turns: количество ходов\n",
        "- victory_status: способ завершения игры\n",
        "- increment_code: контроль времени\n",
        "- white_id, black_id: идентификаторы игроков\n",
        "- white_rating, black_rating: рейтинги игроков\n",
        "- moves: запись ходов\n",
        "- opening_eco, opening_name, opening_ply: информация о дебюте"
      ],
      "metadata": {
        "id": "4-ttf425oY4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['id', 'created_at', 'last_move_at', 'white_id', 'black_id', 'moves'], axis=1, inplace=True)\n",
        "\n",
        "print(\"\\nКоличество пропусков:\")\n",
        "print(df.isnull().sum())\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['winner'] = label_encoder.fit_transform(df['winner'])\n",
        "\n",
        "df['rated'] = df['rated'].map({False: 0, True: 1})\n",
        "\n",
        "categorical_cols = ['victory_status', 'increment_code', 'opening_eco', 'opening_name']\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['turns', 'white_rating', 'black_rating', 'opening_ply']\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "X = df.drop('winner', axis=1)\n",
        "y = df['winner']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nРазмер обучающей выборки: {X_train.shape}\")\n",
        "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
        "\n",
        "def evaluate_model(model, name, X_train, y_train):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_train)\n",
        "\n",
        "    acc = accuracy_score(y_train, y_pred)\n",
        "    prec = precision_score(y_train, y_pred, average='weighted')\n",
        "    rec = recall_score(y_train, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_train, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n{name} на обучающей выборке:\")\n",
        "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
        "    return acc, prec, rec, f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rUU44lHoJBN",
        "outputId": "c3d66b90-db69-494f-b6d5-0a540eeec615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Количество пропусков:\n",
            "rated             0\n",
            "turns             0\n",
            "victory_status    0\n",
            "winner            0\n",
            "increment_code    0\n",
            "white_rating      0\n",
            "black_rating      0\n",
            "opening_eco       0\n",
            "opening_name      0\n",
            "opening_ply       0\n",
            "dtype: int64\n",
            "\n",
            "Размер обучающей выборки: (16046, 2247)\n",
            "Размер тестовой выборки: (4012, 2247)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Дерево решений:\n",
        "   - С использованием `GridSearchCV` осуществить подбор гиперпараметра `DecisionTreeClassifier` (как минимум `max_depth`, `max_features`, другие параметры - по желанию.)\n",
        "   - Вывести значения гиперпараметра и метрик для наилучшей модели `DecisionTreeClassifier` ($accuracy$, $precision$, $recall$, $\\textit{f-measure}$).\n",
        "   - Для полученного наилучшего дерева вывести `feature_importances`, отсортировать их по убыванию.\n",
        "   - Осуществить фильтрацию признаков (по какому-нибудь значению порога важности признака).\n",
        "   - Подобрать лучшую модель с использованием `GridSearchCV` на обучающей выборке с отфильтрованными признаками.\n",
        "   - Вывести полученные гиперпараметры лучшей модели.\n",
        "   - Сравнить метрики до и после фильтрации признаков лучших моделей"
      ],
      "metadata": {
        "id": "nFJU_zEhoJGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_tree = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_tree.fit(X_train, y_train)\n",
        "\n",
        "best_tree = grid_tree.best_estimator_\n",
        "print(f\"\\nЛучшие параметры дерева: {grid_tree.best_params_}\")\n",
        "\n",
        "evaluate_model(best_tree, \"Decision Tree\", X_train, y_train)\n",
        "\n",
        "feature_importances = pd.Series(best_tree.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"\\nFeature Importances:\")\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "threshold = 0.01\n",
        "selected_features = feature_importances[feature_importances > threshold].index.tolist()\n",
        "print(f\"\\nВыбранные признаки после фильтрации (порог >{threshold}):\")\n",
        "print(selected_features)\n",
        "\n",
        "X_train_filtered = X_train[selected_features]\n",
        "X_test_filtered = X_test[selected_features]\n",
        "\n",
        "grid_tree_filtered = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_tree_filtered.fit(X_train_filtered, y_train)\n",
        "\n",
        "best_tree_filtered = grid_tree_filtered.best_estimator_\n",
        "print(f\"\\nЛучшие параметры дерева (на отфильтрованных признаках): {grid_tree_filtered.best_params_}\")\n",
        "\n",
        "print(\"\\n--- Сравнение деревьев ---\")\n",
        "print(\"До фильтрации:\")\n",
        "evaluate_model(best_tree, \"Decision Tree (до)\", X_train, y_train)\n",
        "print(\"После фильтрации:\")\n",
        "evaluate_model(best_tree_filtered, \"Decision Tree (после)\", X_train_filtered, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxxbTDYMoJKn",
        "outputId": "b1962768-8835-4746-f975-e60b47fd8de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры дерева: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2}\n",
            "\n",
            "Decision Tree на обучающей выборке:\n",
            "Accuracy: 0.5032, Precision: 0.6386, Recall: 0.5032, F1-score: 0.3448\n",
            "\n",
            "Feature Importances:\n",
            "opening_ply                          0.079634\n",
            "black_rating                         0.078023\n",
            "opening_eco_C41                      0.060900\n",
            "opening_eco_A04                      0.056965\n",
            "increment_code_5+30                  0.055840\n",
            "increment_code_20+60                 0.052933\n",
            "turns                                0.052357\n",
            "opening_name_Caro-Kann Defense #2    0.039176\n",
            "white_rating                         0.038516\n",
            "increment_code_15+15                 0.035481\n",
            "dtype: float64\n",
            "\n",
            "Выбранные признаки после фильтрации (порог >0.01):\n",
            "['opening_ply', 'black_rating', 'opening_eco_C41', 'opening_eco_A04', 'increment_code_5+30', 'increment_code_20+60', 'turns', 'opening_name_Caro-Kann Defense #2', 'white_rating', 'increment_code_15+15', 'increment_code_30+0', 'opening_name_Pirc Defense: Byrne Variation', 'opening_eco_B07', 'opening_eco_A07', 'opening_name_Crab Opening', 'increment_code_20+20', 'victory_status_outoftime', 'opening_name_Danish Gambit', 'increment_code_10+3', 'opening_name_Pirc Defense', 'rated', 'opening_eco_C21', 'increment_code_10+0', 'victory_status_resign', 'opening_name_Pirc Defense #4', 'opening_name_Center Game: Kieseritzky Variation #3', 'increment_code_15+10']\n",
            "\n",
            "Лучшие параметры дерева (на отфильтрованных признаках): {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 10}\n",
            "\n",
            "--- Сравнение деревьев ---\n",
            "До фильтрации:\n",
            "\n",
            "Decision Tree (до) на обучающей выборке:\n",
            "Accuracy: 0.5032, Precision: 0.6386, Recall: 0.5032, F1-score: 0.3448\n",
            "После фильтрации:\n",
            "\n",
            "Decision Tree (после) на обучающей выборке:\n",
            "Accuracy: 0.5930, Precision: 0.5936, Recall: 0.5930, F1-score: 0.5845\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5929826748099215,\n",
              " 0.5936280960002484,\n",
              " 0.5929826748099215,\n",
              " 0.5844947897105054)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Случайный лес\n",
        "   - Построить случайный лес (`RandomForestClassifier`), c использованием `GridSearchCV` осуществить подбор гиперпараметра.\n",
        "   - Вывести полученные гиперпараметры лучшей модели случайного леса.\n",
        "   - Осуществить фильтрацию признаков.\n",
        "   - Подобрать лучшую модель с использованием `GridSearchCV` на обучающей выборке с отфильтрованными признаками.\n",
        "   - Вывести полученные гиперпараметры лучшей модели случайного леса.\n",
        "   - Сравнить метрики до и после фильтрации признаков лучших моделей."
      ],
      "metadata": {
        "id": "7djZTFzuoJO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_forest = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_forest = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_forest, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_forest.fit(X_train, y_train)\n",
        "\n",
        "best_forest = grid_forest.best_estimator_\n",
        "print(f\"\\nЛучшие параметры случайного леса: {grid_forest.best_params_}\")\n",
        "evaluate_model(best_forest, \"Random Forest\", X_train, y_train)\n",
        "\n",
        "X_train_filtered = X_train[selected_features]\n",
        "X_test_filtered = X_test[selected_features]\n",
        "\n",
        "grid_forest_filtered = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_forest, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_forest_filtered.fit(X_train_filtered, y_train)\n",
        "\n",
        "best_forest_filtered = grid_forest_filtered.best_estimator_\n",
        "print(f\"\\nЛучшие параметры случайного леса (на отфильтрованных признаках): {grid_forest_filtered.best_params_}\")\n",
        "\n",
        "print(\"\\n--- Сравнение случайного леса ---\")\n",
        "print(\"До фильтрации:\")\n",
        "evaluate_model(best_forest, \"Random Forest (до)\", X_train, y_train)\n",
        "print(\"После фильтрации:\")\n",
        "evaluate_model(best_forest_filtered, \"Random Forest (после)\", X_train_filtered, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWHEaLyFoJTD",
        "outputId": "c125408b-737d-4584-b039-1933a20b60d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры случайного леса: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest на обучающей выборке:\n",
            "Accuracy: 0.5328, Precision: 0.6537, Recall: 0.5328, F1-score: 0.4093\n",
            "\n",
            "Лучшие параметры случайного леса (на отфильтрованных признаках): {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 200}\n",
            "\n",
            "--- Сравнение случайного леса ---\n",
            "До фильтрации:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest (до) на обучающей выборке:\n",
            "Accuracy: 0.5328, Precision: 0.6537, Recall: 0.5328, F1-score: 0.4093\n",
            "После фильтрации:\n",
            "\n",
            "Random Forest (после) на обучающей выборке:\n",
            "Accuracy: 0.6584, Precision: 0.6368, Recall: 0.6584, F1-score: 0.6348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6584195438115418,\n",
              " 0.6368017463123653,\n",
              " 0.6584195438115418,\n",
              " 0.6348413559457295)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Метод ближайших соседей:\n",
        "   - С использованием `GridSearchCV` осуществить подбор гиперпараметра `KNeighborsClassifier` (`n_neighbors`).\n",
        "   - Вывести значения гиперпараметра и метрик для наилучшей модели.\n",
        "   - Осуществить фильтрацию признаков.\n",
        "   - Подобрать лучшую модель с использованием `GridSearchCV` на обучающей выборке с отфильтрованными признаками.\n",
        "   - Вывести полученные гиперпараметры лучшей модели случайного леса.\n",
        "   - Сравнить метрики до и после фильтрации признаков."
      ],
      "metadata": {
        "id": "O5Bl8028oJWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_knn_simple = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform'],\n",
        "    'p': [2]\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    param_grid_knn_simple,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "best_knn = grid_knn.best_estimator_\n",
        "print(f\"\\nЛучшие параметры KNN: {grid_knn.best_params_}\")\n",
        "\n",
        "evaluate_model(best_knn, \"KNN\", X_train, y_train)\n",
        "\n",
        "X_train_filtered = X_train[selected_features]\n",
        "X_test_filtered = X_test[selected_features]\n",
        "\n",
        "grid_knn_filtered = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    param_grid_knn_simple,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_knn_filtered.fit(X_train_filtered, y_train)\n",
        "\n",
        "best_knn_filtered = grid_knn_filtered.best_estimator_\n",
        "print(f\"\\nЛучшие параметры KNN (на отфильтрованных признаках): {grid_knn_filtered.best_params_}\")\n",
        "\n",
        "print(\"\\n--- Сравнение KNN ---\")\n",
        "print(\"До фильтрации:\")\n",
        "evaluate_model(best_knn, \"KNN (до)\", X_train, y_train)\n",
        "print(\"После фильтрации:\")\n",
        "evaluate_model(best_knn_filtered, \"KNN (после)\", X_train_filtered, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW8FGhQvoJat",
        "outputId": "a49686cc-7ff0-42a0-e6ad-853980b1ff32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры KNN: {'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
            "\n",
            "KNN на обучающей выборке:\n",
            "Accuracy: 0.7023, Precision: 0.7075, Recall: 0.7023, F1-score: 0.6996\n",
            "\n",
            "Лучшие параметры KNN (на отфильтрованных признаках): {'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n",
            "\n",
            "--- Сравнение KNN ---\n",
            "До фильтрации:\n",
            "\n",
            "KNN (до) на обучающей выборке:\n",
            "Accuracy: 0.7023, Precision: 0.7075, Recall: 0.7023, F1-score: 0.6996\n",
            "После фильтрации:\n",
            "\n",
            "KNN (после) на обучающей выборке:\n",
            "Accuracy: 0.6975, Precision: 0.6946, Recall: 0.6975, F1-score: 0.6937\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6974947027296523,\n",
              " 0.6946446546716438,\n",
              " 0.6974947027296523,\n",
              " 0.6936706084029484)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Если наблюдается улучшение метрик после фильтрации признаков хотя бы для одной из моделей, то для набора отфильтрованных признаков (пересечение множеств отфильтрованных признаков каждой модели или объединение множеств &ndash; не особо важно, главное описать, каким образом получен новый subset данных) заново построить наилучшие модели `KNeighborsClassifier`, `DecisionTreeClassifier`, `RandomForestClassifier`, сравнить модели в пункте 7 на одинаковом полученном наборе отфильтрованных признаков. Иначе &ndash; пропустить этот пункт."
      ],
      "metadata": {
        "id": "CCJgnVA1oJep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_models = {\n",
        "    \"Decision Tree\": best_tree_filtered,\n",
        "    \"Random Forest\": best_forest_filtered,\n",
        "    \"KNN\": best_knn_filtered\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in final_models.items():\n",
        "    model.fit(X_train_filtered, y_train)\n",
        "    y_pred = model.predict(X_test_filtered)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    results.append((name, acc, prec, rec, f1))\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7dGqTBcoQTb",
        "outputId": "b56608ed-0e59-4f0f-c314-2f1b3032022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.5503, Precision: 0.5432, Recall: 0.5503, F1-score: 0.5431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.6129, Precision: 0.5889, Recall: 0.6129, F1-score: 0.5886\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.5698, Precision: 0.5652, Recall: 0.5698, F1-score: 0.5666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Оценка качества построенных моделей:\n",
        "   - Визуализировать любое полученное дерево решений.\n",
        "     > Для вывода названий признаков в граф необходимо задать значение аргумента `feature_names` в `sklearn.tree.export_graphviz`, для вывода названий классов &ndash; `class_names` (перед кодированием целевого признака можно сохранить названия в отдельный массив).\n",
        "   - Сравнить лучшие модели `KNeighborsClassifier`, `DecisionTreeClassifier`, `RandomForestClassifier` на **тестовой выборке**. Привести значения метрик $accuracy$, $precision$, $recall$, $\\textit{f-measure}$."
      ],
      "metadata": {
        "id": "MvjfZ_8KoQZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "class_names = label_encoder.classes_.tolist()\n",
        "feature_names = X_train_filtered.columns.tolist()\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    best_tree_filtered,\n",
        "    out_file=None,\n",
        "    feature_names=feature_names,\n",
        "    class_names=class_names,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")\n",
        "graph.view()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qhoNBw0eoRAE",
        "outputId": "d5513a99-3e03-4417-a3ad-9803ff2c26d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}